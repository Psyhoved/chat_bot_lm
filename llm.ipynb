{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-08-28T11:17:45.366989Z",
     "start_time": "2024-08-28T11:17:45.354977Z"
    }
   },
   "source": "from libs.llm_chat import llama_3_1_8b, create_chain, get_session_history\n",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T11:16:45.016662Z",
     "start_time": "2024-08-28T11:16:41.868115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# chain_hermes = create_chain(model=hermes)\n",
    "chain = create_chain(model=llama_3_1_8b)"
   ],
   "id": "f7f8bc33093a7345",
   "outputs": [],
   "execution_count": 34
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T11:16:36.489585Z",
     "start_time": "2024-08-28T11:16:36.474015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_id = 'саша003'\n",
    "question = 'Привет, какой КБЖУ у онигири?'"
   ],
   "id": "e93b4efa3ec7c28d",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T11:17:48.898206Z",
     "start_time": "2024-08-28T11:17:48.858203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response_content = chain.invoke({\"input\": question}, config={\"configurable\": {\"session_id\": user_id}})\n",
    "response_content"
   ],
   "id": "be89ee444889284e",
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "PostgresChatMessageHistory.__init__() got some positional-only arguments passed as keyword arguments: 'table_name, session_id'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[37], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m response_content \u001B[38;5;241m=\u001B[39m \u001B[43mchain\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minvoke\u001B[49m\u001B[43m(\u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43minput\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43mquestion\u001B[49m\u001B[43m}\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mconfig\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mconfigurable\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43m{\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43msession_id\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[43muser_id\u001B[49m\u001B[43m}\u001B[49m\u001B[43m}\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m response_content\n",
      "File \u001B[1;32mC:\\D\\livemart\\chat_bot_lm\\.venv\\lib\\site-packages\\langchain_core\\runnables\\base.py:5096\u001B[0m, in \u001B[0;36mRunnableBindingBase.invoke\u001B[1;34m(self, input, config, **kwargs)\u001B[0m\n\u001B[0;32m   5088\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minvoke\u001B[39m(\n\u001B[0;32m   5089\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[0;32m   5090\u001B[0m     \u001B[38;5;28minput\u001B[39m: Input,\n\u001B[0;32m   5091\u001B[0m     config: Optional[RunnableConfig] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   5092\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Optional[Any],\n\u001B[0;32m   5093\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Output:\n\u001B[0;32m   5094\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbound\u001B[38;5;241m.\u001B[39minvoke(\n\u001B[0;32m   5095\u001B[0m         \u001B[38;5;28minput\u001B[39m,\n\u001B[1;32m-> 5096\u001B[0m         \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_merge_configs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mconfig\u001B[49m\u001B[43m)\u001B[49m,\n\u001B[0;32m   5097\u001B[0m         \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m{\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mkwargs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs},\n\u001B[0;32m   5098\u001B[0m     )\n",
      "File \u001B[1;32mC:\\D\\livemart\\chat_bot_lm\\.venv\\lib\\site-packages\\langchain_core\\runnables\\history.py:558\u001B[0m, in \u001B[0;36mRunnableWithMessageHistory._merge_configs\u001B[1;34m(self, *configs)\u001B[0m\n\u001B[0;32m    555\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(expected_keys) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m    556\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m parameter_names:\n\u001B[0;32m    557\u001B[0m         \u001B[38;5;66;03m# If arity = 1, then invoke function by positional arguments\u001B[39;00m\n\u001B[1;32m--> 558\u001B[0m         message_history \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_session_history\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    559\u001B[0m \u001B[43m            \u001B[49m\u001B[43mconfigurable\u001B[49m\u001B[43m[\u001B[49m\u001B[43mexpected_keys\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m\n\u001B[0;32m    560\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    561\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    562\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m config:\n",
      "File \u001B[1;32mC:\\D\\livemart\\chat_bot_lm\\libs\\llm_chat.py:138\u001B[0m, in \u001B[0;36mget_session_history\u001B[1;34m(session_id)\u001B[0m\n\u001B[0;32m    128\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_session_history\u001B[39m(session_id: \u001B[38;5;28mstr\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m BaseChatMessageHistory:\n\u001B[0;32m    129\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    130\u001B[0m \u001B[38;5;124;03m    Возвращает историю сообщений для заданной сессии.\u001B[39;00m\n\u001B[0;32m    131\u001B[0m \n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    136\u001B[0m \u001B[38;5;124;03m        BaseChatMessageHistory: Объект истории сообщений чата.\u001B[39;00m\n\u001B[0;32m    137\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 138\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mPostgresChatMessageHistory\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtable_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mTABLE\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    139\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43msession_id\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msession_id\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    140\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43msync_connection\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mCONN_STR2BD\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mTypeError\u001B[0m: PostgresChatMessageHistory.__init__() got some positional-only arguments passed as keyword arguments: 'table_name, session_id'"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T10:59:23.986286Z",
     "start_time": "2024-08-27T10:59:22.939404Z"
    }
   },
   "cell_type": "code",
   "source": [
    "session_history = get_session_history(user_id)\n",
    "session_history"
   ],
   "id": "c2ae9ea9a857ebac",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langchain_community.chat_message_histories.postgres.PostgresChatMessageHistory at 0x1752b248400>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-27T11:02:44.684624Z",
     "start_time": "2024-08-27T11:02:43.549741Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'Human': 'Привет! Когда приедет курьер?'},\n",
       " {'AI': 'Привет! :) Время доставки заказа зависит от выбранного интервала и адреса доставки. Точное время прибытия курьера будет указано в приложении после оформления заказа. Если у вас возникнут вопросы или необходима помощь, обращайтесь в наш Живой Чат, и мы с радостью поможем!'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18,
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "session_history = get_session_history(user_id)\n",
    "\n",
    "# Преобразование сообщений в список словарей\n",
    "messages = []\n",
    "for message in session_history.messages:\n",
    "    if isinstance(message, HumanMessage):\n",
    "        messages.append({\"Human\": message.content})\n",
    "    elif isinstance(message, AIMessage):\n",
    "        messages.append({\"AI\": message.content})\n",
    "messages"
   ],
   "id": "ac0108f59893eec3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T11:18:41.188667Z",
     "start_time": "2024-08-28T11:18:38.408522Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.runnables import RunnableWithMessageHistory\n",
    "from pathlib import Path\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.chat_models import GigaChat\n",
    "from libs.llm_chat import (TEMPERATURE, MAX_TOKENS, VEC_STORE_LOAD_PATH, define_promt, get_history_aware_retriever,\n",
    "                           get_session_history)\n",
    "\n",
    "\n",
    "def create_chain_gigachat(vec_store_path: str | Path = VEC_STORE_LOAD_PATH) -> RunnableWithMessageHistory:\n",
    "    \"\"\"\n",
    "        Создает и возвращает цепочку обработки запросов с учетом истории чата.\n",
    "\n",
    "    Returns:\n",
    "        RunnableWithMessageHistory: Цепочка обработки запросов с учетом истории чата.\n",
    "    \"\"\"\n",
    "    load_dotenv()\n",
    "    GIGACHAT_KEY = os.environ.get('GIGACHAT_KEY')\n",
    "    \n",
    "    chat = GigaChat(credentials=GIGACHAT_KEY, \n",
    "                    verify_ssl_certs=False,\n",
    "                    scope=\"GIGACHAT_API_PERS\",\n",
    "                    model='GigaChat', # попробовать GigaChat-Pro\n",
    "                    temperature=TEMPERATURE,\n",
    "                    max_tokens=MAX_TOKENS)\n",
    "    \n",
    "    prompt = define_promt()\n",
    "\n",
    "    doc_chain = create_stuff_documents_chain(chat, prompt)\n",
    "    history_aware_retriever = get_history_aware_retriever(chat, vec_store_path)\n",
    "\n",
    "    chain = create_retrieval_chain(history_aware_retriever, doc_chain)\n",
    "\n",
    "    # Create a chain\n",
    "    conversational_rag_chain = RunnableWithMessageHistory(\n",
    "        chain,\n",
    "        get_session_history,\n",
    "        input_messages_key=\"input\",\n",
    "        history_messages_key=\"chat_history\",\n",
    "        output_messages_key=\"answer\",\n",
    "    )\n",
    "\n",
    "    return conversational_rag_chain"
   ],
   "id": "5b1e0c4f94c78034",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T11:18:48.864395Z",
     "start_time": "2024-08-28T11:18:42.870482Z"
    }
   },
   "cell_type": "code",
   "source": [
    "chain_gigachat = create_chain_gigachat()\n",
    "chain_gigachat"
   ],
   "id": "8f64ab78acc7bf34",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\D\\livemart\\chat_bot_lm\\.venv\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RunnableWithMessageHistory(bound=RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  chat_history: RunnableBinding(bound=RunnableLambda(_enter_history), config={'run_name': 'load_history'})\n",
       "}), config={'run_name': 'insert_history'})\n",
       "| RunnableBranch(branches=[(RunnableBinding(bound=RunnableLambda(_is_not_async), config={'run_name': 'RunnableWithMessageHistoryInAsyncMode'}), RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "    context: RunnableBinding(bound=RunnableBranch(branches=[(RunnableLambda(lambda x: not x.get('chat_history', False)), RunnableLambda(lambda x: x['input'])\n",
       "             | VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001E4D15BC310>))], default=ChatPromptTemplate(input_variables=['chat_history', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Учитывая историю чата и последний вопрос пользователя,     который может ссылаться на контекст в истории чата, сформулируй отдельный вопрос,     который можно понять без истории чата. НЕ ОТВЕЧАЙ на вопрос, просто переформулируйте его,     если необходимо, и в противном случае верните его как есть.\\n    ')), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])\n",
       "             | GigaChat(credentials='ZGQ0YmJhMzAtY2NkMy00NWUzLWFlYzAtNTkxMmNjMzllODBlOmIwNjhmZWRhLTEyN2MtNDY3YS04NmMxLWVlODBlYjU3M2ViMw==', scope='GIGACHAT_API_PERS', verify_ssl_certs=False, temperature=0.5, max_tokens=500)\n",
       "             | StrOutputParser()\n",
       "             | VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001E4D15BC310>)), config={'run_name': 'retrieve_documents'})\n",
       "  })\n",
       "  | RunnableAssign(mapper={\n",
       "      answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "                context: RunnableLambda(format_docs)\n",
       "              }), config={'run_name': 'format_inputs'})\n",
       "              | ChatPromptTemplate(input_variables=['chat_history', 'context', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template=' Ты - чат-бот Енот, и работаешь в чате сети магазинов хороших продуктов \"Жизньмарт\",\\n    твоя функция - стараться ответить на любой вопрос клиента про работу магазинов \"Жизьмарт\".\\n    Используй в ответах только русский язык! Не отвечай на английском! \\n    Если вопрос не касается контекста, то вежливо и дружелюбно переведи тему и расскажи про Живчики Жизьмарта.\\n\\n    {context}\\n\\n    Используй только этот контекст, чтобы ответить на последний вопрос.\\n    Если ответа нет в контексте, просто позитивно поддержи диалог на тему Жизньмарта!\\n    Если клиент поздоровался с тобой, но НЕ ЗАДАЛ вопрос, тогда поздоровайся и спроси, чем ему помочь!\\n    ')), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])\n",
       "              | GigaChat(credentials='ZGQ0YmJhMzAtY2NkMy00NWUzLWFlYzAtNTkxMmNjMzllODBlOmIwNjhmZWRhLTEyN2MtNDY3YS04NmMxLWVlODBlYjU3M2ViMw==', scope='GIGACHAT_API_PERS', verify_ssl_certs=False, temperature=0.5, max_tokens=500)\n",
       "              | StrOutputParser(), config={'run_name': 'stuff_documents_chain'})\n",
       "    }), config={'run_name': 'retrieval_chain'}), config_factories=[<function Runnable.with_alisteners.<locals>.<lambda> at 0x000001E4D15C70A0>]))], default=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "    context: RunnableBinding(bound=RunnableBranch(branches=[(RunnableLambda(lambda x: not x.get('chat_history', False)), RunnableLambda(lambda x: x['input'])\n",
       "             | VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001E4D15BC310>))], default=ChatPromptTemplate(input_variables=['chat_history', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='Учитывая историю чата и последний вопрос пользователя,     который может ссылаться на контекст в истории чата, сформулируй отдельный вопрос,     который можно понять без истории чата. НЕ ОТВЕЧАЙ на вопрос, просто переформулируйте его,     если необходимо, и в противном случае верните его как есть.\\n    ')), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])\n",
       "             | GigaChat(credentials='ZGQ0YmJhMzAtY2NkMy00NWUzLWFlYzAtNTkxMmNjMzllODBlOmIwNjhmZWRhLTEyN2MtNDY3YS04NmMxLWVlODBlYjU3M2ViMw==', scope='GIGACHAT_API_PERS', verify_ssl_certs=False, temperature=0.5, max_tokens=500)\n",
       "             | StrOutputParser()\n",
       "             | VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001E4D15BC310>)), config={'run_name': 'retrieve_documents'})\n",
       "  })\n",
       "  | RunnableAssign(mapper={\n",
       "      answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "                context: RunnableLambda(format_docs)\n",
       "              }), config={'run_name': 'format_inputs'})\n",
       "              | ChatPromptTemplate(input_variables=['chat_history', 'context', 'input'], input_types={'chat_history': typing.List[typing.Union[langchain_core.messages.ai.AIMessage, langchain_core.messages.human.HumanMessage, langchain_core.messages.chat.ChatMessage, langchain_core.messages.system.SystemMessage, langchain_core.messages.function.FunctionMessage, langchain_core.messages.tool.ToolMessage]]}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], template=' Ты - чат-бот Енот, и работаешь в чате сети магазинов хороших продуктов \"Жизньмарт\",\\n    твоя функция - стараться ответить на любой вопрос клиента про работу магазинов \"Жизьмарт\".\\n    Используй в ответах только русский язык! Не отвечай на английском! \\n    Если вопрос не касается контекста, то вежливо и дружелюбно переведи тему и расскажи про Живчики Жизьмарта.\\n\\n    {context}\\n\\n    Используй только этот контекст, чтобы ответить на последний вопрос.\\n    Если ответа нет в контексте, просто позитивно поддержи диалог на тему Жизньмарта!\\n    Если клиент поздоровался с тобой, но НЕ ЗАДАЛ вопрос, тогда поздоровайся и спроси, чем ему помочь!\\n    ')), MessagesPlaceholder(variable_name='chat_history'), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], template='{input}'))])\n",
       "              | GigaChat(credentials='ZGQ0YmJhMzAtY2NkMy00NWUzLWFlYzAtNTkxMmNjMzllODBlOmIwNjhmZWRhLTEyN2MtNDY3YS04NmMxLWVlODBlYjU3M2ViMw==', scope='GIGACHAT_API_PERS', verify_ssl_certs=False, temperature=0.5, max_tokens=500)\n",
       "              | StrOutputParser(), config={'run_name': 'stuff_documents_chain'})\n",
       "    }), config={'run_name': 'retrieval_chain'}, config_factories=[<function RunnableBinding.with_listeners.<locals>.<lambda> at 0x000001E4D15C71C0>])), config={'run_name': 'RunnableWithMessageHistory'}), get_session_history=<function get_session_history at 0x000001E4ACE56E60>, input_messages_key='input', output_messages_key='answer', history_messages_key='chat_history', history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T11:20:53.107167Z",
     "start_time": "2024-08-28T11:20:53.093220Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import uuid\n",
    "\n",
    "# user_id = 'саша004'\n",
    "user_id = str(uuid.uuid4())\n",
    "question = 'Привет \\nКак получить бесплатный кофе?'\n",
    "user_id"
   ],
   "id": "fd0bcc68d687d02e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ded07b43-933d-45bd-a9f7-cc197f97cddc'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-08-28T11:21:01.990413Z",
     "start_time": "2024-08-28T11:20:58.622954Z"
    }
   },
   "cell_type": "code",
   "source": [
    "response_content = chain_gigachat.invoke({\"input\": question}, config={\"configurable\": {\"session_id\": user_id}})\n",
    "response_content"
   ],
   "id": "7fea27118f1db6c6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Error in RootListenersTracer.on_chain_end callback: KeyError('answer')\n",
      "Error in callback coroutine: KeyError('answer')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Привет \\nКак получить бесплатный кофе?',\n",
       " 'chat_history': [],\n",
       " 'context': [Document(page_content='Гость: Какой кофе мне могут сделать бесплатно по карточке?  \\nБот: Здравствуйте! На главном экране в приложен ии Жизньмарт  появился раздел \\nКофе в подарок, в котором есть копилка. Нажав на акцию с кофе, вы увидите, какие \\nнапитки можно получить бесплатно 💚'),\n",
       "  Document(page_content='Гость: Как сменить данные в профиле?  \\nБот: Здравствуйте! Для этого перейдите в профиль в приложении или на сайте в \\nЛичный Кабинет и внесите нужные изменения. После чего сохраните.'),\n",
       "  Document(page_content='Гость: Как связаться с курьером?  \\nБот: Здравствуйте! В приложении в разделе «Наши магазины» и на сайте в разделе \\n«Адреса магазинов кафе» представлены все номера магазинов – вы можете \\nпозвонить напрямую супергероям, а они сориентируют вас по коммуникации с \\nкурьером :)'),\n",
       "  Document(page_content='Гость: Как сменить номер в приложении?  \\n\"Бот: Здравствуйте! Один номер предназначен для одного аккаунта. При удалении \\nпрофиля все накопленные живчики и бонусы сгорают. Для того, чтобы сменить номер, \\nнужно выйти из текущего аккаунта и создать новый – с новым номером телефона :)')],\n",
       " 'answer': 'Здравствуйте! Чтобы получить бесплатный кофе, нужно зайти в приложение или на сайт Жизньмарт и найти раздел «Кофе в подарок». Там будет указано, какой кофе можно получить бесплатно.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
